Metadata-Version: 2.4
Name: sherlock
Version: 0.1.0
Summary: Intercept LLM API traffic and display token usage in a live dashboard
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: mitmproxy>=10.0.0
Requires-Dist: rich>=13.0.0
Requires-Dist: tiktoken>=0.5.0
Requires-Dist: click>=8.0.0
Dynamic: license-file

# Sherlock

LLM API traffic interceptor and token usage dashboard.

Sherlock intercepts HTTPS traffic to LLM APIs (Anthropic, Google Gemini) and displays a live terminal dashboard showing token usage across your session.

## Installation

```bash
cd /path/to/sherlock
pip install -e .
```

## Setup

### 1. Generate mitmproxy certificates

Run mitmproxy once to generate its CA certificate:

```bash
mitmdump --showhost
# Press Ctrl+C to stop
```

### 2. Install CA certificate

Check certificate status:

```bash
sherlock check-certs
```

Get installation instructions:

```bash
sherlock install-certs
```

## Usage

### Terminal 1: Start Sherlock

```bash
sherlock start
```

Options:
- `--port NUM` - Proxy port (default: 8080)
- `--limit NUM` - Token limit for fuel gauge (default: 200000)
- `--persist` - Save token history to `~/.sherlock/history.json`
- `--save-prompts` - Save all prompts to `~/.sherlock/prompts/`

### Terminal 2: Run your LLM tools

Set proxy environment variables:

```bash
eval $(sherlock env)
```

Then run your LLM-powered tools:

```bash
claude "Hello, world"
```

## Commands

| Command | Description |
|---------|-------------|
| `sherlock start` | Start proxy and dashboard (default) |
| `sherlock check-certs` | Check if CA certificate is installed |
| `sherlock install-certs` | Print CA installation instructions |
| `sherlock env` | Print proxy environment variables |

## Features

- **Live Dashboard**: Real-time token usage tracking with Rich terminal UI
- **Context Fuel Gauge**: Visual progress bar showing cumulative token usage
- **Request Log**: Scrolling table of intercepted requests
- **Prompt Preview**: Shows the last intercepted user prompt
- **History Persistence**: Optionally save token history across sessions
- **Prompt Archive**: Save all intercepted prompts as markdown files

## Supported Providers

- Anthropic (Claude)
- Google Gemini

## Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│                    sherlock CLI (click)                          │
│  Commands: start | check-certs | install-certs | env            │
└─────────────────────────────────────────────────────────────────┘
                                │
                    (sherlock start)
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                         main.py                                  │
│  - Starts mitmproxy as subprocess with interceptor addon        │
│  - Runs Rich dashboard in main thread                           │
│  - Receives intercepted data via file-based IPC                 │
└─────────────────────────────────────────────────────────────────┘
         │                                      │
         ▼                                      ▼
┌─────────────────────────────────────────────────────────────────┐
│   interceptor.py    │            │       dashboard.py           │
│  - mitmproxy addon  │  File IPC  │  - Rich Live UI              │
│  - Filters LLM APIs │ ────────►  │  - Token gauge               │
│  - Parses requests  │            │  - Request log               │
│  - Counts tokens    │            │  - Prompt panel              │
└─────────────────────────────────────────────────────────────────┘
```

## License

MIT
